{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e668c01",
   "metadata": {},
   "source": [
    "# Graph File Pre-Processing\n",
    "\n",
    "Take ROOT files turn them into point clouds which can then be turned into graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d02d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from operator import truth\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import uproot\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "import os\n",
    "\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de5f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take ROOT file and convert to an awkward array\n",
    "def fileToAwk(path):\n",
    "    file = uproot.open(path)\n",
    "    tree = file['tree']\n",
    "    \n",
    "    awk = tree.arrays(tree.keys())\n",
    "    return awk\n",
    "\n",
    "input_features = [\"part_px\", \"part_py\", \"part_pz\", \"part_energy\",\n",
    "                  \"part_deta\", \"part_dphi\", \"part_d0val\", \"part_d0err\", \n",
    "                  \"part_dzval\", \"part_dzerr\", \"part_isChargedHadron\", \"part_isNeutralHadron\", \n",
    "                  \"part_isPhoton\", \"part_isElectron\", \"part_isMuon\" ] # features used to train the model\n",
    "\n",
    " \n",
    "# take AWK dict and convert to a point cloud\n",
    "def awkToPointCloud(awkDict, input_features):\n",
    "    available_features = awkDict.type.keys() # all features\n",
    "\n",
    "    featureVector = []\n",
    "    for jet in tqdm(range(len(awkDict)), total=len(awkDict)):\n",
    "        currJet = awkDict[jet][input_features]\n",
    "        pT = np.array(np.sqrt(currJet['part_px'] ** 2 + currJet['part_py'] ** 2))\n",
    "        # creates numpy array to represent the 4 momenta of all particles in a jet\n",
    "        currJet = np.column_stack((np.array(currJet['part_px']), np.array(currJet['part_py']), \n",
    "                                   np.array(currJet['part_pz']), np.array(currJet['part_energy']), pT\n",
    "                                   , np.array(currJet['part_deta']), np.array(currJet['part_dphi']), \n",
    "                                   np.array(currJet[\"part_d0val\"]), np.array(currJet[\"part_d0err\"]), \n",
    "                                   np.array(currJet[\"part_dzval\"]), np.array(currJet[\"part_dzerr\"]), \n",
    "                                   np.array(currJet[\"part_isChargedHadron\"]), np.array(currJet[\"part_isNeutralHadron\"]), \n",
    "                                   np.array(currJet[\"part_isPhoton\"]), np.array(currJet[\"part_isElectron\"]), \n",
    "                                   np.array(currJet[\"part_isMuon\"])))\n",
    "        \n",
    "        featureVector.append(currJet)\n",
    "    return np.array(featureVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eac452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "#take point cloud and build KNN graph\n",
    "def buildKNNGraph(points, k):\n",
    "    \n",
    "    # Compute k-nearest neighbors\n",
    "    tree = cKDTree(points)\n",
    "    dists, indices = tree.query(points, k+1)  # +1 to exclude self\n",
    "    \n",
    "    # Build adjacency matrix\n",
    "    num_points = len(points)\n",
    "    adj_matrix = np.zeros((num_points, num_points))\n",
    "    for i in range(num_points):\n",
    "        for j in indices[i, 1:]:  # exclude self\n",
    "            adj_matrix[i, j] = 1\n",
    "            adj_matrix[j, i] = 1\n",
    "    return adj_matrix\n",
    "\n",
    "# take adjacency matrix and turn it into a DGL graph\n",
    "def adjacencyToDGL(adj_matrix):\n",
    "    adj_matrix = sp.coo_matrix(adj_matrix)\n",
    "    g_dgl = dgl.from_scipy(adj_matrix)\n",
    "        \n",
    "    return g_dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53a1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import dgl\n",
    "import pickle\n",
    "\n",
    "# wrap the functionality of fileToAwk and awkToPointCloud in a function to return a point cloud numpy array\n",
    "def fileToPointCloudArray(jetType, input_features):\n",
    "    filepath = f'/Volumes/Yash SSD/JetClass/JetRoots/{jetType}_000.root' # original root file\n",
    "    savepath = f'/Volumes/Yash SSD/JetClass/PointClouds/{jetType}.npy' # save file\n",
    "    awk = fileToAwk(filepath)\n",
    "    nparr = awkToPointCloud(awk, input_features)\n",
    "    \n",
    "    return nparr\n",
    "\n",
    "# wrap the functionality of fileToPointCloudArray and the \n",
    "def fileToGraph(jetType, k=3, save=True):\n",
    "    print(f'Starting processing on {jetType} jets')\n",
    "    pointCloudArr = fileToPointCloudArray(jetType, input_features)\n",
    "    \n",
    "    saveFilePath = f'/Volumes/Yash SSD/Multi Level Jet Tagging/{jetType}.pkl'\n",
    "    \n",
    "    savedGraphs = []\n",
    "    for idx, pointCloud in tqdm(enumerate(pointCloudArr), leave=False, total=len(pointCloudArr)):\n",
    "        try:\n",
    "            adj_matrix = buildKNNGraph(pointCloud, k)\n",
    "            graph = adjacencyToDGL(adj_matrix)\n",
    "            \n",
    "            graph.ndata['feat'] = torch.tensor(pointCloud, dtype=torch.float32)\n",
    "            \n",
    "            savedGraphs.append(graph)\n",
    "            \n",
    "            del adj_matrix, graph\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    \n",
    "    if save:\n",
    "        with open(saveFilePath, 'wb') as f:\n",
    "            pickle.dump(savedGraphs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        \n",
    "        del pointCloudArr, savedGraphs\n",
    "        \n",
    "    print(f'Graphs for {jetType} processing complete!')\n",
    "        \n",
    "    return savedGraphs\n",
    "\n",
    "def groupToGraph(jetTypeList, groupName):\n",
    "    allGraphs = []\n",
    "    for jetType in jetTypeList:\n",
    "        allGraphs += fileToGraph(jetType, save=False)\n",
    "    \n",
    "    saveFilePath = f'/Volumes/Yash SSD/Multi Level Jet Tagging/{groupName}.pkl' \n",
    "    return allGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "894f0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing on HToBB jets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 100000/100000 [02:50<00:00, 586.30it/s]\n",
      "/var/folders/0q/bs1s8dl52_g396mh_5rg0zb40000gn/T/ipykernel_940/2564396636.py:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(featureVector)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs for HToBB processing complete!\n",
      "Starting processing on HToCC jets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 100000/100000 [02:49<00:00, 590.68it/s]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs for HToCC processing complete!\n",
      "Starting processing on HToGG jets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 100000/100000 [02:48<00:00, 591.84it/s]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs for HToGG processing complete!\n",
      "Starting processing on HToWW2Q1L jets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 100000/100000 [02:49<00:00, 590.44it/s]\n",
      "  2%|▊                                  | 2263/100000 [00:00<00:17, 5720.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 is out of bounds for axis 1 with size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████▋                       | 31602/100000 [00:05<00:11, 5832.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 is out of bounds for axis 1 with size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████▌                   | 42762/100000 [00:07<00:09, 5857.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 is out of bounds for axis 1 with size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████▌                  | 45678/100000 [00:07<00:09, 5805.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 3 is out of bounds for axis 1 with size 3\n",
      "index 3 is out of bounds for axis 1 with size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████▊      | 81894/100000 [00:18<00:03, 5856.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 is out of bounds for axis 1 with size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████▏    | 85930/100000 [00:18<00:02, 5685.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 3 is out of bounds for axis 1 with size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████▏  | 91757/100000 [00:19<00:01, 5824.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 3 is out of bounds for axis 1 with size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs for HToWW2Q1L processing complete!\n",
      "Starting processing on HToWW4Q jets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 100000/100000 [02:52<00:00, 580.67it/s]\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs for HToWW4Q processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# process all jetTypes\n",
    "Higgs = ['HToBB', 'HToCC', 'HToGG', 'HToWW2Q1L', 'HToWW4Q']\n",
    "Vector = ['WToQQ', 'ZToQQ']\n",
    "Top = ['TTBar', 'TTBarLep']\n",
    "QCD = ['ZJetsToNuNu']\n",
    "Emitter = ['Emitter-Vector', 'Emitter-Top', 'Emitter-Higgs', 'Emitter-QCD']\n",
    "allJets = Higgs + Vector + Top + QCD\n",
    "\n",
    "#for jetType in allJets:\n",
    "#    fileToGraph(jetType)\n",
    "\n",
    "allGraphs = groupToGraph(Higgs, \"Emitter-Higgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a4fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/Volumes/Yash SSD/Multi Level Jet Tagging/Emitter-Higgs.pkl', 'wb') as f:\n",
    "    pickle.dump(allGraphs, f)\n",
    "    \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795262b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d7337e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8de6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f3920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
